{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> **Livrable n°1 : Classification binaire** </center>\n",
    "\n",
    "‎ \n",
    "\n",
    "Réalisé par le **groupe n°2** :\n",
    "- BERTHO Lucien\n",
    "- BOSACKI Paul\n",
    "- GAURE Warren\n",
    "- GRENOUILLET Théo\n",
    "- VALLEMONT Hugo\n",
    "\n",
    "\n",
    "‎\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sommaire**\n",
    "\n",
    "1. [Mise en contexte](#contexte)\n",
    "2. [Objectif du livrable](#objectif)\n",
    "3. [Importation des bibliothèques](#import)\n",
    "4. [Préparation et chargement des données](#load)\n",
    "5. [Exploration et visualisation des données](#exploration)\n",
    "6. [Configuration de l'environnement](#configuration)\n",
    "7. [Choix de l'architecture](#architecture)\n",
    "8. [Réalisation du modèle](#modele)\n",
    "9.  [Entraînement et évaluation du modèle](#train)\n",
    "10. [Amélioration du modèle](#amelioration)\n",
    "11. [Tuning des paramètres du modèle](#tuning)\n",
    "12. [Modèle final](#final)\n",
    "13. [Conclusion](#conclusion)\n",
    "\n",
    "‎ \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. <a id='contexte'>Mise en contexte</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’entreprise TouNum est spécialisée dans la numérisation de documents, qu’il s’agisse de textes ou d’images. Ses services sont particulièrement sollicités par des entreprises cherchant à transformer leur base documentaire papier en fichiers numériques exploitables. Aujourd’hui, TouNum souhaite aller plus loin en enrichissant son offre avec des outils basés sur le Machine Learning.\n",
    "\n",
    "En effet, certains clients disposent d’un volume considérable de documents à numériser et expriment un besoin croissant pour des solutions de catégorisation automatique. Une telle innovation leur permettrait d’optimiser le traitement et l’exploitation de leurs données numérisées. Toutefois, TouNum ne dispose pas en interne des compétences nécessaires pour concevoir et mettre en place ces technologies.\n",
    "\n",
    "C’est dans ce cadre que notre équipe de spécialistes en Data Science du CESI est sollicitée. Notre mission consiste à développer une première solution intégrant du captioning automatique : un système capable d’analyser des photographies et de générer une légende descriptive de manière autonome.\n",
    "\n",
    "Heureusement, TouNum possède déjà plusieurs milliers d’images annotées, ce qui constituera une ressource précieuse pour entraîner les modèles de Machine Learning à partir d’un apprentissage supervisé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. <a id='objectif'>Objectif du livrable</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TouNum souhaite automatiser la sélection des photos destinées à l'annotation. Ce livrable propose une méthode de classification basée sur les réseaux de neurones pour filtrer les images qui ne sont pas des photos. La solution reposera sur l'architecture de réseau retenue en fonction des résultats obtenus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. <a id='import'>Importation des bibliothèques</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import os\n",
    "import shutil\n",
    "import datetime\n",
    "import keras_tuner as kt\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. <a id='import'>Adaptation pour GPU</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin d'entrainer nos modèles sur le GPU de nos ordinateurs, une configuration est nécéssaire. Celle-ci va optimiser la demande de mémoire pour qu'elle soit allouer de manière croissante. Cela va permettre d'éviter d'allouer le maximum de mémoire dès le début et éviter une surutilisation de celle-ci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. <a id='load'>Préparation et chargement des données</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois les bibliothèques importées, nous pouvons commencer à préparer le terrain en amont et charger les données pour qu'elles puissent être utilisées dans notre pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. <a>Filtrage des données</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un premier temps, nous devons veiller à ce que nous aillons bien reçu uniquement des images, c'est-à-dire vérifier qu'il n'y ait pas d'intrus comme des fichiers textes ou autres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_directory = \"dataset_livrable_1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_image(filename):\n",
    "    try:\n",
    "        with Image.open(filename) as img:\n",
    "            img.verify()\n",
    "        return True\n",
    "    except (UnidentifiedImageError, OSError):\n",
    "        return False\n",
    "\n",
    "def move_non_images(directory):\n",
    "    dump_directory = \"dump\"\n",
    "    os.makedirs(dump_directory, exist_ok = True)\n",
    "    \n",
    "    for folder, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(folder, file)\n",
    "            if not is_image(file_path):\n",
    "                print(f\"Déplacement de {file_path} dans le dossier dump/\")\n",
    "                dest_path = os.path.join(dump_directory, file)\n",
    "                try:\n",
    "                    shutil.move(file_path, dest_path)\n",
    "                except:\n",
    "                    print(\"Erreur lors du déplacement\")\n",
    "                \n",
    "move_non_images(dataset_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. <a>Vérification des images</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, nous devons nous assurer du bon état des images reçues, c'est-à-dire vérifier si elles n'ont pas été corrompues ou mal formatées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_image(path):\n",
    "    try:\n",
    "        img_raw = tf.io.read_file(path)\n",
    "        _ = tf.image.decode_image(img_raw, channels=3)\n",
    "        return (path, True)\n",
    "    except Exception:\n",
    "        return (path, False)\n",
    "\n",
    "def clean_corrupted_images(directory, extensions=(\"jpg\", \"jpeg\", \"png\"), max_workers=8):\n",
    "    image_paths = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(extensions):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "\n",
    "    print(f\"Scan de {len(image_paths)} images dans {directory}\")\n",
    "\n",
    "    corrupted_count = 0\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(is_valid_image, path) for path in image_paths]\n",
    "        for future in as_completed(futures):\n",
    "            path, is_valid = future.result()\n",
    "            if not is_valid:\n",
    "                try:\n",
    "                    os.remove(path)\n",
    "                    corrupted_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur de suppression {path} : {e}\")\n",
    "\n",
    "    print(f\"Vérification terminée : {corrupted_count} image(s) corrompue(s) supprimée(s).\")\n",
    "    \n",
    "\n",
    "clean_corrupted_images(dataset_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "──────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. <a>Gestion des logs</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous créons ici un dossier qui va nous permettre de stocker les logs qui seront utilisés par [TensorBoard](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "──────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4. <a>Chargement des images</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les images doivent être séparées en deux ensembles : un pour l'entraînement du modèle, l'autre pour son évaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_h = 128\n",
    "image_w = 128\n",
    "batch_s = 16\n",
    "\n",
    "train_set, test_set = keras.utils.image_dataset_from_directory(\n",
    "    dataset_directory,\n",
    "    label_mode = \"int\",\n",
    "    batch_size = batch_s,\n",
    "    image_size = (image_h, image_w),\n",
    "    seed = 42,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"both\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Exploration des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que les données ont pu être préparées et chargées, nous pouvons nous intéresser de plus près à elles, à commencer par le nom des classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. <a>Nom des classes</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_set.class_names\n",
    "print(f\"Classes détectées : {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous retrouvons bien les 5 classes attendues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "──────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. <a>Répartition des données</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous regardons maintenant la répartition des données entre les classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_class_distribution(dataset, name):\n",
    "    label_counts = collections.Counter(label.numpy() for _, label in dataset.unbatch())\n",
    "\n",
    "    classes = {0: \"peintures\", 1: \"photos\", 2: \"schémas\", 3: \"croquis\", 4: \"textes scannés\"}\n",
    "\n",
    "    total = sum(label_counts.values())\n",
    "  \n",
    "    labels = []\n",
    "    counts = []\n",
    "    percentages = []\n",
    "\n",
    "    for label_id in sorted(label_counts):\n",
    "        class_name = classes.get(label_id, f\"Classe inconnue ({label_id})\")\n",
    "        count = label_counts[label_id]\n",
    "        labels.append(class_name)\n",
    "        counts.append(count)\n",
    "        percentages.append(count / total * 100)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(labels, counts)\n",
    "\n",
    "    for bar, pct in zip(bars, percentages):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, height + 1, f\"{pct:.1f}%\", ha='center', va='bottom')\n",
    "\n",
    "    plt.title(f\"Répartition des classes ({name}_set - {total} images)\")\n",
    "    plt.xlabel(\"Classe\")\n",
    "    plt.ylabel(\"Nombre d'images\")\n",
    "    plt.xticks(rotation=15)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_class_distribution(train_set, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_class_distribution(test_set, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut l'observer sur les histogrammes générés, la répartition des données entre les différentes classes est déséquilibrée dans les deux ensembles. Bien que cela ne soit pas gênant dans le set de test car nous souhaitons avoir des conditions proches de la réalité, cela peut poser problème lors de l'entraînement de notre modèle, qui risque d'être biaisé envers les classes majoritaires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "──────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3. <a>Taille des données</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous affichons maintenant la taille des données, information pouvant être utile par la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_set.take(1)))\n",
    "print(f\"Tensor des images : {images.shape}\")\n",
    "print(f\"Tensor des labels : {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "──────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4. <a>Affichage des images</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, nous affichons quelques images pour voir plus en détail ce à quoi nous avons affaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 8))\n",
    "for images, labels in train_set.take(10):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i].numpy()])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. <a id='configuration'>Configuration de l'environnement</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour optimiser les performances des calculs, nous allons configurer les données à l’aide de deux fonctions : `Dataset.cache` et `Dataset.prefetch`.  \n",
    "- [`Dataset.cache`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#cache) stocke les données en mémoire pour éviter les accès répétés au disque.  \n",
    "- [`Dataset.prefetch`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#prefetch) permet de traiter un élément en arrière-plan pendant l'entraînement ou l'évaluation.  \n",
    "\n",
    "En combinant ces techniques, nous réduirons significativement le temps de traitement et la charge computationnelle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:orange;\">Non utilisé dans le cas de l'utilisation d'un GPU </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "#train_set = train_set.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\n",
    "#test_set = test_set.cache().prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. <a id='architecture'>Choix de l'architecture</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les **Convolutional Neural Networks (CNN)** sont devenus l’architecture de référence pour les tâches de classification d’images, notamment en classification multi-classes. Leur efficacité repose sur leur capacité à exploiter la structure spatiale locale des images à travers des opérations de convolution, permettant ainsi une extraction hiérarchique des caractéristiques visuelles (bords, formes, textures…).\n",
    "\n",
    "Historiquement, LeCun et al. (1998) ont démontré la pertinence des CNN dans la reconnaissance de chiffres manuscrits avec LeNet-5. Cette approche a été fortement étendue avec AlexNet (Krizhevsky et al., 2012), qui a surpassé toutes les autres méthodes sur le défi ImageNet, impliquant la classification dans 1000 classes différentes. Depuis, des architectures plus profondes comme VGG, ResNet ou EfficientNet ont confirmé la domination des CNN dans ce domaine (Rawat & Wang, 2017).\n",
    "\n",
    "De nombreux frameworks modernes (TensorFlow, PyTorch) proposent des implémentations standardisées de CNN pour la classification multi-classes, et les performances obtenues dépassent largement celles des méthodes classiques (SVM, k-NN, etc.) sur des datasets variés.\n",
    "\n",
    "En résumé, le choix d’un CNN est justifié par :\n",
    "- Sa capacité à apprendre automatiquement des représentations visuelles pertinentes\n",
    "- Son efficacité démontrée sur des benchmarks multi-classes (ex : CIFAR-10, ImageNet)\n",
    "- Sa large adoption dans la recherche et l’industrie pour les tâches de vision par ordinateur\n",
    "\n",
    "**Sources**\n",
    "1. Lecun, Yann & Bottou, Leon & Bengio, Y. & Haffner, Patrick. (1998). Gradient-Based Learning Applied to Document Recognition. Proceedings of the IEEE. 86. 2278 - 2324. 10.1109/5.726791.\n",
    "2. Krizhevsky, Alex & Sutskever, Ilya & Hinton, Geoffrey. (2012). ImageNet Classification with Deep Convolutional Neural Networks. Neural Information Processing Systems. 25. 10.1145/3065386.\n",
    "3. Rawat, Waseem & Wang, Zenghui. (2017). Deep Convolutional Neural Networks for Image Classification: A Comprehensive Review. Neural Computation. 29. 2352-2449. 10.1162/NECO_a_00990."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. <a id='modele'>Réalisation du modèle</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que le choix de l'architecture est fait, nous pouvons commencer à créer le modèle que nous allons utiliser pour classifier les images envoyées par l'entreprise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1 <a id='modele'>Création du modèle de base</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre modèle sera structuré autour des blocs suivants :  \n",
    "- Une **couche de rescaling** pour normaliser les valeurs des composantes RGB des pixels dans l'intervalle `[0;1]`.  \n",
    "- Une **première convolution** avec 16 filtres de taille 3x3 (`Conv2D`), suivie d'un **max pooling** pour réduire la dimension spatiale.  \n",
    "- Une **seconde convolution** utilisant 32 filtres de taille 3x3.  \n",
    "- Une **troisième convolution** avec 64 filtres de taille 3x3.  \n",
    "- Une **transformation en vecteur** via une opération d'aplatissement (`Flatten`).  \n",
    "- Une **couche dense** de 128 unités pour capturer les caractéristiques extraites.  \n",
    "- Enfin, une **sortie entièrement connectée** avec 1 unité, correspondant à la classe cible.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "def create_model(use_dropout=False, show_summary=True, hparams=None,activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Rescaling(1.0 / 255))\n",
    "\n",
    "    # Use hyperparameters if available, otherwise default values\n",
    "    num_units = hparams.get('units', 128) if hparams else 128\n",
    "    activation = hparams.get('activation', 'relu') if hparams else 'relu'\n",
    "    dropout_rate = hparams.get('dropout', 0.5) if hparams else 0.5\n",
    "\n",
    "    model.add(layers.Conv2D(16, (3, 3), padding='same', activation=activation))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    if use_dropout and dropout_rate:\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3, 3), padding='same', activation=activation))\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='same', activation=activation))\n",
    "\n",
    "    if use_dropout and dropout_rate:\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(num_units, activation=activation))\n",
    "\n",
    "    if use_dropout and dropout_rate:\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    learning_rate = hparams.get('lr', 0.001) if hparams else 0.001\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate) if hparams else 'adam'\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    if show_summary:\n",
    "        model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'optimiseur [`Adam`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) est choisi pour sa capacité d'adaptation et sa rapidité de convergence. La fonction de perte [`SparseCategoricalCrossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy), quant à elle, est utilisée car jugée plus efficace en mémoire que d'autres fonctions et bien adaptée à la classification multi-classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2 <a id='modele'>Tuning des hyperparamètres</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette section, nous allons effectuer le tuning des hyperparamètres, c’est-à-dire le réglage manuel ou automatique des paramètres qui contrôlent le comportement du modèle, comme le taux d’apprentissage, la taille des couches ou la taille des batchs. Cela permet d’optimiser les performances du modèle en trouvant la combinaison de paramètres qui offre les meilleurs résultats sur les données de validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus précisément, nous cherchons à optimiser les paramètres suivants :\n",
    "- L'usage (ou non) des couches de **Dropout**\n",
    "- Le **pas d'apprentissage** (learning rate)\n",
    "- La **fonction d'activation** donnant de meilleurs résultats entre [`relu`](https://www.tensorflow.org/api_docs/python/tf/keras/activations/relu) et [`tanh`](https://www.tensorflow.org/api_docs/python/tf/keras/activations/tanh)\n",
    "- Le **nombre d'epochs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ce faire, nous utilisons l'algorithme [`Hyperband`](https://keras.io/keras_tuner/api/tuners/hyperband/) de la librairie [Keras Tuner](https://keras.io/keras_tuner/) pour chercher ces hyperparamètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    units = hp.Int(\"units\", min_value=32, max_value=512, step=32)\n",
    "    activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "    dropout = hp.Boolean(\"dropout\")\n",
    "\n",
    "    hparams = {\n",
    "        \"dense_units\": units,\n",
    "        \"activation\": activation,\n",
    "        \"dropout_3\": 0.5 if dropout else 0.0 \n",
    "    }\n",
    "\n",
    "    model = create_model(\n",
    "        use_dropout=dropout,  \n",
    "        show_summary=False,\n",
    "        hparams=hparams\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    hypermodel = build_model,\n",
    "    objective = 'val_accuracy',\n",
    "    max_epochs = 10,\n",
    "    factor = 3,\n",
    "    directory = 'hyperband',\n",
    "    project_name = 'hyperband_test'\n",
    ")\n",
    "stop_early = keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_accuracy',\n",
    "    patience = 5,\n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'optimiseur [`Adam`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) est choisi pour sa capacité d'adaptation et sa rapidité de convergence. La fonction de perte [`SparseCategoricalCrossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy), quant à elle, est utilisée car jugée plus efficace en mémoire que d'autres fonctions et bien adaptée à la classification multi-classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. <a id='train'>Entraînement et évaluation du modèle</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec le modèle créé, nous pouvons désormais procéder à son entraînement et à son évaluation avec les ensembles de données à notre disposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1. <a>Graphiques</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons des graphiques afin de visualiser les courbes d’accuracy pour suivre en temps réel les performances du modèle sur les données d’entraînement et de validation. Cela permet de détecter rapidement les signes de surapprentissage ou de sous-apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de générer les graphiques, nous créons les deux callbacks suivants :\n",
    "- [`TensorBoard`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard?hl=en) : Il permet de visualiser en temps réel l’évolution des métriques et du modèle, facilitant l’analyse et le suivi de l’entraînement.\n",
    "- [`ModelCheckpoint`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint?hl=en) : Ce callback permet de sauvegarder automatiquement le meilleur modèle au cours de l’entraînement, évitant ainsi de perdre les meilleures performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = TensorBoard(\n",
    "    log_dir = log_dir,\n",
    "    histogram_freq = 1\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath = 'checkpoints/best_model.keras',\n",
    "    monitor = 'val_accuracy',\n",
    "    save_best_only = True,\n",
    "    save_weights_only = False,\n",
    "    mode = 'max',\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "callbacks.append(tensorboard_callback)\n",
    "callbacks.append(checkpoint_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme nous l'avons observé lors de la phase d'exploration des données, il y a un déséquilibre notable dans la répartition des données entre les classes des deux ensembles. Pour palier à ce problème lors de l'entraînement de notre modèle, nous allons ajouter des poids aux classes, qui seront générés grâce à la méthode [`compute_class_weight`](https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html) de la librairie [scikit-learn](https://scikit-learn.org/stable/index.html). Ceci aura pour effet de renforcer l’importance des classes minoritaires lors de l’apprentissage, afin que le modèle ne privilégie pas uniquement les classes majoritaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([label.numpy() for _, label in train_set.unbatch()])\n",
    "class_weights = compute_class_weight(class_weight = \"balanced\", classes = np.unique(y_train), y = y_train)\n",
    "weights_dict = {cls: weight for cls, weight in zip(np.unique(y_train), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_set, test_set, epochs=10, use_hyperparameters=False, tuner=None):\n",
    "    if use_hyperparameters and tuner:\n",
    "        train_size = int(0.8 * len(train_set))\n",
    "        val_size = len(train_set) - train_size\n",
    "        train_dataset = train_set.take(train_size)\n",
    "        val_dataset = train_set.skip(train_size)\n",
    "\n",
    "        tuner.search(train_dataset, validation_data=val_dataset, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "        best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "        model = tuner.hypermodel.build(best_hps)\n",
    "        history = model.fit(train_dataset, validation_data=val_dataset, epochs=epochs, validation_split=0.2)\n",
    "    else:\n",
    "        history = model.fit(\n",
    "            train_set,\n",
    "            validation_data=test_set,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "    \n",
    "    accuracy = history.history['accuracy']\n",
    "    validation_accuracy = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    validation_loss = history.history['val_loss']\n",
    "    \n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(len(accuracy)), accuracy, label='Training Accuracy')\n",
    "    plt.plot(range(len(accuracy)), validation_accuracy, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title(f\"Training and Validation Accuracy - {model.name}\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(len(loss)), loss, label='Training Loss')\n",
    "    plt.plot(range(len(loss)), validation_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(f\"Training and Validation Loss - {model.name}\")\n",
    "    \n",
    "    plt.savefig(\"training_results.png\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:yellow;\">TODO</b>\n",
    "\n",
    "Analyser les résultats obtenus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "──────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2. <a>Matrice de confusion</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons une matrice de confusion pour évaluer plus finement les performances d’un modèle en montrant les erreurs de classification pour chaque classe. Elle met en évidence les classes confondues et aide à cibler les axes d’amélioration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_true = []\n",
    "\n",
    "for images, labels in test_set:\n",
    "    X_test.append(images)\n",
    "    y_true.append(labels)\n",
    "\n",
    "X_test = np.concatenate(X_test)\n",
    "y_true = np.concatenate(y_true)\n",
    "\n",
    "def display_matrix(model, X_test = X_test, y_true = y_true, class_names = class_names):\n",
    "    y_pred_proba = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_proba, axis = 1)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    display = ConfusionMatrixDisplay(cm, display_labels = class_names)\n",
    "    display.plot(cmap = plt.cm.Blues)\n",
    "    plt.title(\"Matrice de confusion\")\n",
    "    plt.xticks(rotation = 45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_matrix(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:yellow;\">TODO</b>\n",
    "\n",
    "Analyser les résultats obtenus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.3. <a>TensorBoard</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons TensorBoard pour visualiser de manière interactive l’entraînement du modèle, en suivant l’évolution des métriques, la structure du réseau et d’autres informations utiles pour le debug et l’optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. <a id='amelioration'>Amélioration du modèle</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de palier au surapprentissage observé et d’améliorer la généralisation du modèle, plusieurs techniques de régularisation ont été retenues :\n",
    "\n",
    "- [Data Augmentation](#augmentation): Cette technique consister à générer artificiellement de nouvelles images en appliquant des transformations aléatoires aux données existantes. Elle permet d'améliorer la généralisation du modèle en le rendant plus robuste aux variations comme l’orientation, la luminosité ou le zoom.\n",
    "\n",
    "- [Dropout](#dropout) : Cette méthode consiste à désactiver aléatoirement un certain pourcentage de neurones à chaque itération lors de l'entraînement. Cela empêche le modèle de devenir trop dépendant de certaines connexions et encourage l'apprentissage de représentations plus robustes. Une valeur typique se situe entre 0.2 et 0.5 selon la complexité du réseau.\n",
    "\n",
    "- [Early-Stopping](#early-stopping) : Cette technique permet d'arrêter automatiquement l'entraînement lorsque la performance sur l’ensemble de validation commence à se dégrader. Elle évite d’entraîner le modèle trop longtemps, ce qui pourrait mener à un surajustement aux données d’entraînement. Un paramètre clé est la `patience`, qui définit le nombre d’époques d'attente avant d'interrompre l'entraînement si aucune amélioration n'est observée.\n",
    "\n",
    "En testant et, potentiellement, combinant ces différentes approches, nous parviendrons à obtenir un modèle plus stable, robuste, et capable de mieux généraliser sur des données non vues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "──────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.1. <a id='augmentation'>Data Augmentation</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cette approche, nous allons appliquer des transformations aux données d'entraînement, comme un retournement aléatoire, une rotation de 10% et d’un zoom vertical de 10%. Les données de test restent inchangées pour permettre au modèle de pouvoir faire des prédictions sur un cas réel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(input_shape = (image_h, image_w, 3), mode = 'horizontal_and_vertical'),\n",
    "    layers.RandomRotation(factor = 0.1, fill_mode = 'nearest'),\n",
    "    layers.RandomZoom(height_factor = 0.1, fill_mode = 'nearest'),\n",
    "])\n",
    "\n",
    "augmented_train_set = train_set.map(lambda x, y: (data_augmentation(x, training = True), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_with_augmentation = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons procéder à l'entraînement de cette version du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_model(model_with_augmentation, train_set = augmented_train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, nous affichons les résultat sous forme d'une matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_matrix(model_with_augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:yellow;\">TODO</b>\n",
    "\n",
    "Analyser les résultats obtenus.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "**Notes lors des tests (avec le dataset du WKS2)**\n",
    "- Méthode efficace pour gérer le surapprentissage\n",
    "- Les courbes d'accuracy augmentent ensemble de manière cohérente\n",
    "- Pas de divergence apparente\n",
    "- Très bonne capacité de généralisation vu que la courbe de Validation Accuracy est souvent au-dessus de celle de la Training Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "──────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2. <a id='dropout'>Dropout</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cette approche, nous ajoutons les couches de Dropout suivantes :\n",
    "- La première avec un taux de 25% après le MaxPooling\n",
    "- La seconde de 25% aussi après la troisième couche de convolution\n",
    "- La dernière avec un taux de 50% après la première couche Dense.\n",
    "Nous nous sommes inspirés de l’approche de [Keras pour le dataset MNIST](https://github.com/keras-team/keras/blob/keras-2/examples/mnist_cnn.py).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_with_dropout = create_model(use_dropout = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons procéder à l'entraînement de cette version du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_model(model_with_dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, nous affichons les résultat sous forme d'une matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_matrix(model_with_dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En procédant à l'entraînement de ce modèle comme nous l'avons vu auparavant, nous obtenons les graphiques suivants :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Insérer graphiques </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:yellow;\">TODO</b>\n",
    "\n",
    "Analyser les résultats obtenus.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "**Notes lors des tests (avec le dataset du WKS2)**\n",
    "- Apprend trop vite (Traning Accuracy > 95%) mais ne généralise pas mieux pour autant (Validation Loss en hausse)\n",
    "- La Validation Accuracy se stabilise au bout de la 6ème époque\n",
    "- Écart significatif entre la Traning Accuracy et la Validation Accuracy => surapprentissage\n",
    "- Le Dropout seul semble ne pas suffire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "──────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3. <a id='early-stopping'>Early Stopping</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cette approche, nous ajoutons un Early Stopping basé sur la perte de validation, avec une patience de 5 époques, afin d’interrompre l’entraînement dès que le modèle cesse de s’améliorer et de conserver les meilleurs poids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_accuracy',\n",
    "    patience = 2,\n",
    "    mode = 'max',\n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_with_early_stopping = create_model(\"Early Stopping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons procéder à l'entraînement de cette version du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks.append(early_stopping)\n",
    "#train_model(model_with_early_stopping, epochs = 20)\n",
    "#callbacks.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, nous affichons les résultat sous forme d'une matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_matrix(model_with_early_stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Insérer graphiques </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:yellow;\">TODO</b>\n",
    "\n",
    "Analyser les résultats obtenus.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "**Notes lors des tests (avec le dataset du WKS2)**\n",
    "- Apprend trop vite (Traning Accuracy > 95%) mais ne généralise pas mieux pour autant\n",
    "- Traning Accuracy proche de 100% à la fin + écart avec Validation Accuracy => surapprentissage\n",
    "- La Validation Loss augmente, ce qui est un autre signe du surapprentissage\n",
    "- Méthode insuffisante à elle seule pour prévenir l'overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. <a id='final'>Modèle final</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:yellow;\">TODO sur les explications</b>\n",
    "\n",
    "<b style=\"color:orange;\">Use of the hyperparamater</b>\n",
    "\n",
    "Indiquer et justifier le choix du modèle final à l'aide des résultats observés. Faire la passe sur ses caractéristiques, à savoir :\n",
    "- Paramètres\n",
    "- Fonction de perte\n",
    "- Algorithme d'optimisation utilisé pour l'entraînement\n",
    "\n",
    "Inclure un schéma du modèle réalisé grâce à cet [outil](https://alexlenail.me/NN-SVG/LeNet.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_hyperparameters = True\n",
    "if use_hyperparameters:\n",
    "    train_size = int(0.8 * len(train_set))  # 80% for training\n",
    "    val_size = len(train_set) - train_size  # 20% for validation\n",
    "\n",
    "    train_dataset = train_set.take(train_size)\n",
    "    val_dataset = train_set.skip(train_size)\n",
    "\n",
    "    tuner.search(train_dataset, validation_data=val_dataset, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    model = create_model(use_dropout=True, hparams=best_hps.values)\n",
    "else:\n",
    "    model = create_model(use_dropout=True)\n",
    "\n",
    "callbacks.append(early_stopping)\n",
    "model = train_model(model, train_set=augmented_train_set, test_set=test_set, epochs=20, use_hyperparameters=use_hyperparameters, tuner=tuner)\n",
    "\n",
    "display_matrix(model)\n",
    "model.save(\"model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. <a id='quid'>Quid de la classification binaire ?</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette section, nous allons comparer les performances de notre modèle lorsqu’il est entraîné sur cinq classes différentes face à une version binaire ne distinguant plus que “photos” et “non-photos”. Nous utiliserons la même architecture de réseau, mais nous réduirons le jeu de données à deux classes afin d’évaluer l’impact que peut avoir le nombre de classes sur la précision, la complexité du modèle ainsi que d'autres métriques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12.1. <a id='quid'>Création du modèle binaire</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_binary, test_set_binary = keras.utils.image_dataset_from_directory(\n",
    "    dataset_directory,\n",
    "    label_mode = \"int\",\n",
    "    batch_size = batch_s,\n",
    "    image_size = (image_h, image_w),\n",
    "    seed = 42,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"both\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_index = class_names.index(\"Photo\")\n",
    "\n",
    "def convert_label_to_binary(image, label):\n",
    "    return image, tf.cast(tf.equal(label, photo_index), tf.int32)\n",
    "\n",
    "train_set_binary = train_set_binary.map(convert_label_to_binary)\n",
    "test_set_binary = test_set_binary.map(convert_label_to_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_binary = train_set_binary.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\n",
    "test_set_binary = test_set_binary.cache().prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_model = Sequential()\n",
    "\n",
    "binary_model.add(layers.Rescaling(1./255))\n",
    "binary_model.add(layers.Conv2D(16, (3, 3), padding = 'same', activation = 'relu'))\n",
    "binary_model.add(layers.MaxPooling2D((2, 2)))\n",
    "binary_model.add(layers.Dropout(0.25))\n",
    "binary_model.add(layers.Conv2D(32, (3, 3), padding = 'same', activation = 'relu'))\n",
    "binary_model.add(layers.Conv2D(64, (3, 3), padding = 'same', activation = 'relu'))\n",
    "binary_model.add(layers.Dropout(0.25))\n",
    "binary_model.add(layers.Flatten())\n",
    "binary_model.add(layers.Dense(128, activation = 'relu'))\n",
    "binary_model.add(layers.Dropout(0.5))\n",
    "binary_model.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "binary_model.compile(\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 0.001),\n",
    "    loss = keras.losses.BinaryCrossentropy(from_logits = False),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_weights = compute_class_weight(\n",
    "    class_weight = \"balanced\",\n",
    "    classes = np.array([0, 1]),\n",
    "    y = np.array([label.numpy() for image, label in train_set_binary.unbatch()])\n",
    ")\n",
    "\n",
    "binary_weights_dict = {0: binary_weights[0], 1: binary_weights[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_binary = []\n",
    "y_true_binary = []\n",
    "\n",
    "for images, labels in test_set_binary:\n",
    "    X_test_binary.append(images)\n",
    "    y_true_binary.append(labels)\n",
    "\n",
    "X_test_binary = np.concatenate(X_test_binary)\n",
    "y_true_binary = np.concatenate(y_true_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_train_set_binary = train_set_binary.map(lambda x, y: (data_augmentation(x, training = True), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12.2. <a id='quid'>Entraînement du modèle binaire</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(binary_model, train_set = augmented_train_set_binary, test_set = test_set_binary, weights = binary_weights_dict)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_matrix(binary_model, X_test = X_test_binary, y_true = y_true_binary, class_names = ['Non-photo', 'Photo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12.3. <a id='quid'>Comparaison des performances</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. <a id='conclusion'>Conclusion</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:yellow;\">TODO</b>\n",
    "\n",
    "Écrire la conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}