{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> **Livrable n°1 :** </center>\n",
    "### <center><i> **Classification binaire** </i></center>\n",
    "\n",
    "‎ \n",
    "‎\n",
    "\n",
    "Document réalisé par le **groupe n°X**, composé de :\n",
    "- GAURE Warren\n",
    "- Membre n°2\n",
    "- Membre n°3\n",
    "- Membre n°4\n",
    "\n",
    "‎\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sommaire**\n",
    "\n",
    "1. [Mise en contexte](#contexte)\n",
    "2. [Objectif du livrable](#objectif)\n",
    "3. [Importation des bibliothèques](#import)\n",
    "4. [Chargement des données](#load)\n",
    "5. [Exploration et visualisation des données](#exploration)\n",
    "6. [Configuration de l'environnement](#configuration)\n",
    "7. [Le réseau de neurones convolutif (CNN)](#cnn)\n",
    "8. [Item #8](#item8)\n",
    "9. [Item #9](#item9)\n",
    "10. [Item #10](#item10)\n",
    "\n",
    "‎ \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. <a id='contexte'>Mise en contexte</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’entreprise TouNum est spécialisée dans la numérisation de documents, qu’il s’agisse de textes ou d’images. Ses services sont particulièrement sollicités par des entreprises cherchant à transformer leur base documentaire papier en fichiers numériques exploitables. Aujourd’hui, TouNum souhaite aller plus loin en enrichissant son offre avec des outils basés sur le Machine Learning.\n",
    "\n",
    "En effet, certains clients disposent d’un volume considérable de documents à numériser et expriment un besoin croissant pour des solutions de catégorisation automatique. Une telle innovation leur permettrait d’optimiser le traitement et l’exploitation de leurs données numérisées. Toutefois, TouNum ne dispose pas en interne des compétences nécessaires pour concevoir et mettre en place ces technologies.\n",
    "\n",
    "C’est dans ce cadre que notre équipe de spécialistes en Data Science du CESI est sollicitée. Notre mission consiste à développer une première solution intégrant du captioning automatique : un système capable d’analyser des photographies et de générer une légende descriptive de manière autonome.\n",
    "\n",
    "Heureusement, TouNum possède déjà plusieurs milliers d’images annotées, ce qui constituera une ressource précieuse pour entraîner les modèles de Machine Learning à partir d’un apprentissage supervisé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. <a id='objectif'>Objectif du livrable</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'entreprise souhaitant automatiser la sélection de photos pour l'annotation, ce livrable fournira une méthode de classification se basant sur les réseaux de neurones, afin de filtrer les images n'étant pas des photos du jeu de données de départ. La solution s'appuyera sur l'architecture de réseau de neurones retenue à la vue des résultats obtenus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. <a id='import'>Importation des bibliothèques</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. <a id='load'>Chargement des données</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant procéder au chargement des données, à savoir les archives contenant les images fournies par TouNum.\n",
    "\n",
    "Pour ce faire, nous commençons d'abord par établir quelques variables importantes, comme le dossier où se trouve les images et les paramètres pour l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './dataset_livrable_1'\n",
    "image_h = 180\n",
    "image_w = 180\n",
    "batch_s = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que cela est fait, nous devons désormais partager les donnnées en deux ensembles, un destiné à l'*entraînement* du modèle et l'autre pour le *test* de ce dernier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    labels = 'inferred',\n",
    "    validation_split = 0.2,\n",
    "    subset = \"training\",\n",
    "    seed = 42,\n",
    "    image_size = (image_h, image_w),\n",
    "    batch_size = batch_s\n",
    ")\n",
    "\n",
    "test_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    labels = 'inferred',\n",
    "    validation_split = 0.2,\n",
    "    subset = \"validation\",\n",
    "    seed = 42,\n",
    "    image_size = (image_h, image_w),\n",
    "    batch_size = batch_s\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La sortie indique la présence de **XXXX** fichiers au total, dont **XXXX** appartenant au jeu d'entraînement et **XXXX** au jeu de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. <a id='exploration'>Exploration et visualisation des données</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois les données réparties dans les deux ensembles, nous pouvons nous intéresser de plus près à elles en commençant d'abord par afficher le nom des labels et déterminer leur répartition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_set.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_distribution(train_set, test_set):\n",
    "    class_count_train = np.zeros(len(class_names))\n",
    "    class_count_test = np.zeros(len(class_names))\n",
    "    \n",
    "    for label in train_set.labels:\n",
    "        class_count_train[label.numpy()] += 1\n",
    "    \n",
    "    for label in test_set.labels:\n",
    "        class_count_test[label.numpy()] += 1\n",
    "    \n",
    "    for class_name, train_count, test_count in zip(class_names, class_count_train, class_count_test):\n",
    "        class_total_count = train_count + test_count\n",
    "        train_percentage = train_count / class_total_count\n",
    "        test_percentage = test_count / class_total_count\n",
    "        print(f'{class_name} : {class_total_count} images in total -> {train_count} for training ({train_percentage:.2f}%) and {test_count} ({test_percentage:.2f}%) for testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous observons que la répartition des données est assez similaire entre chaque label, il n'y aura donc aucun problème à ce niveau.\n",
    "\n",
    "Nous pouvons maintenant afficher quelques images pour regarder plus en détail ce à quoi nous avons affaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "for images, labels in train_set.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. <a id='configuration'>Configuration de l'environnement</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant configurer les données afin d'améliorer les performances lors des calculs que nous serons amenés à effectuer. Pour faire cela, nous allons utiliser deux fonctions : `Dataset.cache` et `Dataset.prefetch`. Elles nous permettent, respectivement, de maintenir les données en cache dans la mémoire et d'effectuer le prétraitement de l'élément courant du jeu de données en même temps que l'entraînement ou l'évaluation. Ces deux méthodes feront gagner du temps et réduiront de manière non-négligeable la complexité computationnelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_set = train_set.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "test_set = test_set.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. <a id='cnn'>Le réseau de neurones convolutif (CNN)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons fait le choix d'utiliser une architecture basée sur les réseaux de neurones convolutifs (CNN) car ils sont parfaits pour la classification binaire d’images. Ils détectent automatiquement les motifs et les formes sans qu’on ait besoin d’extraire les caractéristiques à la main. Contrairement aux réseaux classiques (MLP), qui traitent chaque pixel séparément, les CNN tiennent compte des relations entre pixels, ce qui leur permet de mieux reconnaître les structures visuelles. En utilisant des filtres partagés, ils réduisent le nombre de paramètres à apprendre, rendant l’entraînement plus efficace et évitant le surapprentissage. Grâce au pooling, ils restent aussi performants même si un objet apparaît à un autre endroit dans l’image. En combinant ces atouts, les CNN offrent une solution puissante et optimisée pour cette tâche de classification."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
