{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> **Livrable n°1 :** </center>\n",
    "### <center><i> **Classification binaire** </i></center>\n",
    "\n",
    "‎ \n",
    "‎\n",
    "\n",
    "Document réalisé par le **groupe n°X**, composé de :\n",
    "- GAURE Warren\n",
    "- Membre n°2\n",
    "- Membre n°3\n",
    "- Membre n°4\n",
    "\n",
    "‎\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sommaire**\n",
    "\n",
    "1. [Mise en contexte](#contexte)\n",
    "2. [Objectif du livrable](#objectif)\n",
    "3. [Importation des bibliothèques](#import)\n",
    "4. [Chargement des données](#load)\n",
    "5. [Visualisation des données](#visualization)\n",
    "6. [Item #6](#item6)\n",
    "7. [Item #7](#item7)\n",
    "8. [Item #8](#item8)\n",
    "9. [Item #9](#item9)\n",
    "10. [Item #10](#item10)\n",
    "\n",
    "‎ \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. <a id='contexte'>Mise en contexte</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’entreprise TouNum est spécialisée dans la numérisation de documents, qu’il s’agisse de textes ou d’images. Ses services sont particulièrement sollicités par des entreprises cherchant à transformer leur base documentaire papier en fichiers numériques exploitables. Aujourd’hui, TouNum souhaite aller plus loin en enrichissant son offre avec des outils basés sur le Machine Learning.\n",
    "\n",
    "En effet, certains clients disposent d’un volume considérable de documents à numériser et expriment un besoin croissant pour des solutions de catégorisation automatique. Une telle innovation leur permettrait d’optimiser le traitement et l’exploitation de leurs données numérisées. Toutefois, TouNum ne dispose pas en interne des compétences nécessaires pour concevoir et mettre en place ces technologies.\n",
    "\n",
    "C’est dans ce cadre que notre équipe de spécialistes en Data Science du CESI est sollicitée. Notre mission consiste à développer une première solution intégrant du captioning automatique : un système capable d’analyser des photographies et de générer une légende descriptive de manière autonome.\n",
    "\n",
    "Heureusement, TouNum possède déjà plusieurs milliers d’images annotées, ce qui constituera une ressource précieuse pour entraîner les modèles de Machine Learning à partir d’un apprentissage supervisé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. <a id='objectif'>Objectif du livrable</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'entreprise souhaitant automatiser la sélection de photos pour l'annotation, ce livrable fournira une méthode de classification se basant sur les réseaux de neurones, afin de filtrer les images n'étant pas des photos du jeu de données de départ. La solution s'appuyera sur l'architecture de réseau de neurones retenue à la vue des résultats obtenus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. <a id='import'>Importation des bibliothèques</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. <a id='load'>Chargement des données</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant procéder au chargement des données, à savoir les archives contenant les images fournies par TouNum.\n",
    "\n",
    "Pour ce faire, nous commençons d'abord par établir quelques variables importantes, comme le dossier où se trouve les images et les paramètres pour l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './dataset_livrable_1'\n",
    "image_h = 180\n",
    "image_w = 180\n",
    "batch_s = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que cela est fait, nous devons désormais partager les donnnées en deux ensembles, un destiné à l'*entraînement* du modèle et l'autre pour le *test* de ce dernier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"training\",\n",
    "    seed = 42,\n",
    "    image_size = (image_h, image_w),\n",
    "    batch_size = batch_s\n",
    ")\n",
    "\n",
    "test_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"validation\",\n",
    "    seed = 42,\n",
    "    image_size = (image_h, image_w),\n",
    "    batch_size = batch_s\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La sortie indique la présence de **XXXX** fichiers au total, dont **XXXX** appartenant au jeu d'entraînement et **XXXX** au jeu de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. <a id='exploration'>Exploration et visualisation des données</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois les données réparties dans les deux ensembles, nous pouvons nous intéresser de plus près à elles en commençant d'abord par afficher le nom des labels et déterminer leur répartition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_set.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_distribution(train_set, test_set):\n",
    "    class_count_train = np.zeros(len(class_names))\n",
    "    class_count_test = np.zeros(len(class_names))\n",
    "    \n",
    "    for images, labels in train_set:\n",
    "        for label in labels:\n",
    "            class_count_train[label.numpy()] += 1\n",
    "    \n",
    "    for images, labels in test_set:\n",
    "        for label in labels:\n",
    "            class_count_test[label.numpy()] += 1\n",
    "    \n",
    "    for class_name, train_count, test_count in zip(class_names, class_count_train, class_count_test):\n",
    "        class_total_count = train_count + test_count\n",
    "        train_percentage = train_count / class_total_count\n",
    "        test_percentage = test_count / class_total_count\n",
    "        print(f'{class_name} : {class_total_count} images in total -> {train_count} for training ({train_percentage:.2f}%) and {test_count} ({test_percentage:.2f}%) for testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous observons que la répartition des données est assez similaire entre chaque label, il n'y aura donc aucun problème à ce niveau.\n",
    "\n",
    "Nous pouvons maintenant afficher quelques images pour regarder plus en détail ce à quoi nous avons affaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "for images, labels in train_set.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
