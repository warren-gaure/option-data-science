{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> **Livrable n°1 :** </center>\n",
    "### <center><i> **Classification binaire** </i></center>\n",
    "\n",
    "‎ \n",
    "‎\n",
    "\n",
    "Document réalisé par le **groupe n°X**, composé de :\n",
    "- GAURE Warren\n",
    "- Membre n°2\n",
    "- Membre n°3\n",
    "- Membre n°4\n",
    "\n",
    "‎\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sommaire**\n",
    "\n",
    "1. [Mise en contexte](#contexte)\n",
    "2. [Objectif du livrable](#objectif)\n",
    "3. [Importation des bibliothèques](#import)\n",
    "4. [Chargement des données](#load)\n",
    "5. [Exploration et visualisation des données](#exploration)\n",
    "6. [Configuration de l'environnement](#configuration)\n",
    "7. [Choix de l'architecture](#architecture)\n",
    "8. [Réalisation du modèle](#modele)\n",
    "9. [Entraînement et évaluation du modèle](#train)\n",
    "10. [Amélioration du modèle](#amelioration)\n",
    "11. [Modèle final](#final)\n",
    "12. [Conclusion](#conclusion)\n",
    "\n",
    "‎ \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. <a id='contexte'>Mise en contexte</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’entreprise TouNum est spécialisée dans la numérisation de documents, qu’il s’agisse de textes ou d’images. Ses services sont particulièrement sollicités par des entreprises cherchant à transformer leur base documentaire papier en fichiers numériques exploitables. Aujourd’hui, TouNum souhaite aller plus loin en enrichissant son offre avec des outils basés sur le Machine Learning.\n",
    "\n",
    "En effet, certains clients disposent d’un volume considérable de documents à numériser et expriment un besoin croissant pour des solutions de catégorisation automatique. Une telle innovation leur permettrait d’optimiser le traitement et l’exploitation de leurs données numérisées. Toutefois, TouNum ne dispose pas en interne des compétences nécessaires pour concevoir et mettre en place ces technologies.\n",
    "\n",
    "C’est dans ce cadre que notre équipe de spécialistes en Data Science du CESI est sollicitée. Notre mission consiste à développer une première solution intégrant du captioning automatique : un système capable d’analyser des photographies et de générer une légende descriptive de manière autonome.\n",
    "\n",
    "Heureusement, TouNum possède déjà plusieurs milliers d’images annotées, ce qui constituera une ressource précieuse pour entraîner les modèles de Machine Learning à partir d’un apprentissage supervisé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. <a id='objectif'>Objectif du livrable</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'entreprise souhaitant automatiser la sélection de photos pour l'annotation, ce livrable fournira une méthode de classification se basant sur les réseaux de neurones, afin de filtrer les images n'étant pas des photos du jeu de données de départ. La solution s'appuyera sur l'architecture de réseau de neurones retenue à la vue des résultats obtenus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. <a id='import'>Importation des bibliothèques</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. <a id='load'>Chargement des données</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant procéder au chargement des données, à savoir les archives contenant les images fournies par TouNum.\n",
    "\n",
    "Pour ce faire, nous commençons d'abord par établir quelques variables importantes, comme le dossier où se trouve les images et les paramètres pour l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './dataset_livrable_1'\n",
    "image_h = 180\n",
    "image_w = 180\n",
    "batch_s = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que cela est fait, nous devons désormais partager les donnnées en deux ensembles, un destiné à l'*entraînement* du modèle et l'autre pour le *test* de ce dernier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = keras.utils.image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"training\",\n",
    "    seed = 42,\n",
    "    image_size = (image_h, image_w),\n",
    "    batch_size = batch_s\n",
    ")\n",
    "\n",
    "test_set = keras.utils.image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"validation\",\n",
    "    seed = 42,\n",
    "    image_size = (image_h, image_w),\n",
    "    batch_size = batch_s\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La sortie indique la présence de **XXXX** fichiers au total, dont **XXXX** appartenant au jeu d'entraînement et **XXXX** au jeu de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. <a id='exploration'>Exploration et visualisation des données</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois les données réparties dans les deux ensembles, nous pouvons nous intéresser de plus près à elles en commençant d'abord par afficher le nom des labels et déterminer leur répartition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_set.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_distribution(train_set, test_set):\n",
    "    class_count_train = np.zeros(len(class_names))\n",
    "    class_count_test = np.zeros(len(class_names))\n",
    "    \n",
    "    for label in train_set.labels:\n",
    "        class_count_train[label.numpy()] += 1\n",
    "    \n",
    "    for label in test_set.labels:\n",
    "        class_count_test[label.numpy()] += 1\n",
    "    \n",
    "    for class_name, train_count, test_count in zip(class_names, class_count_train, class_count_test):\n",
    "        class_total_count = train_count + test_count\n",
    "        train_percentage = train_count / class_total_count\n",
    "        test_percentage = test_count / class_total_count\n",
    "        print(f'{class_name} : {class_total_count} images in total -> {train_count} for training ({train_percentage:.2f}%) and {test_count} ({test_percentage:.2f}%) for testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous observons que la répartition des données est assez similaire entre chaque label, il n'y aura donc aucun problème à ce niveau.\n",
    "\n",
    "Nous pouvons maintenant afficher quelques images pour regarder plus en détail ce à quoi nous avons affaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "for images, labels in train_set.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, nous affichons la taille des données, ce qui pourrait être utile pour gérer les performances de notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_set.take(1)))\n",
    "print(f\"Tensor des images : {images.shape}\")\n",
    "print(f\"Tensor des labels : {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. <a id='configuration'>Configuration de l'environnement</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant configurer les données afin d'améliorer les performances lors des calculs que nous serons amenés à effectuer. Pour faire cela, nous allons utiliser deux fonctions : `Dataset.cache` et `Dataset.prefetch`. Elles nous permettent, respectivement, de maintenir les données en cache dans la mémoire et d'effectuer le prétraitement de l'élément courant du jeu de données en même temps que l'entraînement ou l'évaluation. Ces deux méthodes feront gagner du temps et réduiront de manière non-négligeable la complexité computationnelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_set = train_set.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "test_set = test_set.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. <a id='architecture'>Choix de l'architecture</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons fait le choix d'utiliser une architecture basée sur les réseaux de neurones convolutifs (CNN) car ils sont parfaits pour la classification binaire d’images. Ils détectent automatiquement les motifs et les formes sans qu’on ait besoin d’extraire les caractéristiques à la main. Contrairement aux réseaux classiques (MLP - Multilayer Perceptron), qui traitent chaque pixel séparément, les CNN tiennent compte des relations entre pixels, ce qui leur permet de mieux reconnaître les structures visuelles. En utilisant des filtres partagés, ils réduisent le nombre de paramètres à apprendre, rendant l’entraînement plus efficace et évitant le surapprentissage. En combinant ces atouts, les CNN offrent une solution puissante et optimisée pour cette tâche de classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. <a id='modele'>Réalisation du modèle</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que le choix de l'architecture est fait, nous pouvons commencer à créer le modèle que nous allons utiliser pour classifier les images envoyées par l'entreprise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre modèle sera structuré autour des blocs suivants :  \n",
    "- Une **couche de rescaling** pour normaliser les valeurs des composantes RGB des pixels dans l'intervalle `[0;1]`.  \n",
    "- Une **première convolution** avec 16 filtres de taille 3x3 (`Conv2D`), suivie d'un **max pooling** pour réduire la dimension spatiale.  \n",
    "- Une **seconde convolution** utilisant 32 filtres de taille 3x3.  \n",
    "- Une **troisième convolution** avec 64 filtres de taille 3x3.  \n",
    "- Une **transformation en vecteur** via une opération d'aplatissement (`Flatten`).  \n",
    "- Une **couche dense** de 128 unités pour capturer les caractéristiques extraites.  \n",
    "- Enfin, une **sortie entièrement connectée** de 5 unités, correspondant aux classes cibles.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de labels du dataset et de neurones de la dernière couche du modèle\n",
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "    layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    layers.Conv2D(16, (3, 3), padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "    layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'optimiseur [`Adam`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) est choisi pour sa capacité d'adaptation et sa rapidité de convergence, combinant les avantages de [`Momentum`](https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/MomentumOptimizer) et [`RMSprop`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop).\n",
    "\n",
    "La fonction de perte [`SparseCategoricalCrossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy) est utilisée car elle est plus efficace en mémoire pour des labels entiers et bien adaptée à la classification multi-classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code suivant va permettre d'avoir un résumé du modèle tel qu'il est à ce stade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. <a id='train'>Entraînement et évaluation du modèle</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec le modèle créé, nous pouvons désormais procéder à son entraînement et son évaluation avec les ensembles de données à notre disposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "history = model.fit(\n",
    "    train_set,\n",
    "    validation_data = test_set,\n",
    "    epochs = epochs\n",
    ")\n",
    "\n",
    "accuracy = history.history['accuracy']\n",
    "validation_accuracy = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "validation_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, accuracy, label='Training Accuracy')\n",
    "plt.plot(epochs_range, validation_accuracy, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, validation_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:yellow;\">TODO</b>\n",
    "\n",
    "Analyser les résultats et parler du sur-apprentissage ou sous-apprentissage ainsi que de la potentielle instabilité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. <a id='amelioration'>Amélioration du modèle</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:yellow;\">TODO</b>\n",
    "\n",
    "Écrire un big paragpraphe décrivant les techniques de régularisation pouvant être appliquées pour améliorer les performances du modèle.\n",
    "\n",
    "Les techniques retenues sont :\n",
    "- [`Data Augmentation`](https://www.tensorflow.org/tutorials/images/data_augmentation#data_augmentation_2) (cf. WKS n°2)\n",
    "- [`Dropout`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) (cf. WKS n°2)\n",
    "- [`Early-Stopping`](https://keras.io/api/callbacks/early_stopping/)\n",
    "- [`L1 (Lasso)`](https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/L1?hl=en)\n",
    "- [`L2 (Ridge)`](https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/L2?hl=en)\n",
    "\n",
    "Faire ça sous forme de liste et penser à ajouter les liens vers les noms des techniques pour faire en sorte que ça soit un mini-sommaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.1. <a id='data-augmentation'>Data Augmentation</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:yellow;\">TODO</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "──────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2. <a id='dropout'>Dropout</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:yellow;\">TODO</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "──────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3. <a id='early-stopping'>Early Stopping</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:yellow;\">TODO</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "──────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.4. <a id='l1'>Régularisation L1</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:yellow;\">TODO</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "──────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.5. <a id='l2'>Régularisation L2</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:yellow;\">TODO</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "──────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.6. Data Augmentation & Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:yellow;\">TODO</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "──────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.7. Data Augmentation & Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:yellow;\">TODO</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "──────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.7. Data Augmentation, Dropout & Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:yellow;\">TODO</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "──────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.8. Elastic Net (L1 + L2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:yellow;\">TODO</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. <a id='final'>Modèle final</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:yellow;\">TODO</b>\n",
    "\n",
    "Indiquer et justifier le choix du modèle final à l'aide des résultats observés. Faire la passe sur ses caractéristiques, à savoir :\n",
    "- Paramètres\n",
    "- Fonction de perte\n",
    "- Algorithme d'optimisation utilisé pour l'entraînement\n",
    "\n",
    "Inclure un schéma du modèle réalisé grâce à cet [outil](https://alexlenail.me/NN-SVG/LeNet.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. <a id='conclusion'>Conclusion</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:yellow;\">TODO</b>\n",
    "\n",
    "Écrire la conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
