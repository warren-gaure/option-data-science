{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> **Livrable n°2 : Traitement d'images** </center>\n",
    "\n",
    "‎ \n",
    "\n",
    "Réalisé par le **groupe n°2** :\n",
    "- BERTHO Lucien\n",
    "- BOSACKI Paul\n",
    "- GAURE Warren\n",
    "- GRENOUILLET Théo\n",
    "- VALLEMONT Hugo\n",
    "\n",
    "\n",
    "‎\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sommaire**\n",
    "\n",
    "1. [Mise en contexte](#contexte)\n",
    "2. [Objectif du livrable](#objectif)\n",
    "3. [Importation des bibliothèques](#import)\n",
    "4. [Prétraitement et exploration des données](#pretraitement)\n",
    "5. [Item #5](#item5)\n",
    "6. [Item #6](#item6)\n",
    "7. [Item #7](#item7)\n",
    "8. [Item #8](#item8)\n",
    "9. [Item #9](#item9)\n",
    "10. [Item #10](#item10)\n",
    "\n",
    "‎ \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. <a id='contexte'>Mise en contexte</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’entreprise TouNum est spécialisée dans la numérisation de documents, qu’il s’agisse de textes ou d’images. Ses services sont particulièrement sollicités par des entreprises cherchant à transformer leur base documentaire papier en fichiers numériques exploitables. Aujourd’hui, TouNum souhaite aller plus loin en enrichissant son offre avec des outils basés sur le Machine Learning.\n",
    "\n",
    "En effet, certains clients disposent d’un volume considérable de documents à numériser et expriment un besoin croissant pour des solutions de catégorisation automatique. Une telle innovation leur permettrait d’optimiser le traitement et l’exploitation de leurs données numérisées. Toutefois, TouNum ne dispose pas en interne des compétences nécessaires pour concevoir et mettre en place ces technologies.\n",
    "\n",
    "C’est dans ce cadre que notre équipe de spécialistes en Data Science du CESI est sollicitée. Notre mission consiste à développer une première solution intégrant du captioning automatique : un système capable d’analyser des photographies et de générer une légende descriptive de manière autonome.\n",
    "\n",
    "Heureusement, TouNum possède déjà plusieurs milliers d’images annotées, ce qui constituera une ressource précieuse pour entraîner les modèles de Machine Learning à partir d’un apprentissage supervisé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. <a id='objectif'>Objectif du livrable</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cette seconde étape du workflow, il est demandé de traiter les images qui seront destinées à être annotées. Ce livrable propose une méthode de traitement basée sur les auto-encodeurs à convolution afin de débruiter les images fournies et de pouvoir les reconstituer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. <a id='import'>Importation des bibliothèques</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, Dropout, UpSampling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. <a id='pretraitement'>Prétraitement et exploration des données</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois les bibliothèques importées, nous pouvons désormais gérer les données qui nous ont été données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. <a>Vérification des images</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À l'instar de la première étape du workflow, nous vérifions le bon état des images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_image(path):\n",
    "    try:\n",
    "        img_raw = tf.io.read_file(path)\n",
    "        _ = tf.image.decode_image(img_raw, channels=3)\n",
    "        return (path, True)\n",
    "    except Exception:\n",
    "        return (path, False)\n",
    "\n",
    "def clean_corrupted_images(directory, extensions=(\"jpg\", \"jpeg\", \"png\"), max_workers=8):\n",
    "    image_paths = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(extensions):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "\n",
    "    print(f\"Scan de {len(image_paths)} images dans {directory}\")\n",
    "\n",
    "    corrupted_count = 0\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(is_valid_image, path) for path in image_paths]\n",
    "        for future in as_completed(futures):\n",
    "            path, is_valid = future.result()\n",
    "            if not is_valid:\n",
    "                try:\n",
    "                    os.remove(path)\n",
    "                    corrupted_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur de suppression {path} : {e}\")\n",
    "\n",
    "    print(f\"Vérification terminée : {corrupted_count} image(s) corrompue(s) supprimée(s).\")\n",
    "    \n",
    "\n",
    "clean_corrupted_images(dataset_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il s'avérait qu'aucune image a été corrompue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "──────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. <a>Chargement des données</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après vérification, nous pouvons charger les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_h = 128\n",
    "image_w = 128\n",
    "batch_s = 16\n",
    "\n",
    "dataset = keras.utils.image_dataset_from_directory(\n",
    "    directory = \"dataset_livrable_1/Photo\",\n",
    "    label_mode = None,\n",
    "    batch_size = batch_s,\n",
    "    image_size = (image_h, image_w),\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "dataset_2 = keras.utils.image_dataset_from_directory(\n",
    "    directory = dataset_directory,\n",
    "    label_mode = None,\n",
    "    batch_size = batch_s,\n",
    "    image_size = (image_h, image_w),\n",
    "    seed = 42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La sortie indique la présence de **148** images en tout, ce qui rendra le traitement de ces dernières plus rapide que durant l'étape précédente !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "──────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. <a>Prétraitement des données</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Étant donné que nous travaillons à nouveau avec des images, c'est-à-dire des ensembles de pixels dont les valeurs sont comprises entre 0 et 255, nous devons les mettre à dans l'intervalle `[0, 1]` afin de mieux les traiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x: tf.cast(x, tf.float32) / 255.0)\n",
    "dataset_2 = dataset_2.map(lambda x: tf.cast(x, tf.float32) / 255.0)\n",
    "X = []\n",
    "\n",
    "for batch in dataset:\n",
    "    X.append(batch.numpy())\n",
    "\n",
    "for batch in dataset_2:\n",
    "    X.append(batch.numpy())\n",
    "    \n",
    "dataset = np.concatenate(X)\n",
    "print(dataset.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "──────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4. <a>Affichage des images</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que le prétraitement est fait, nous pouvons afficher des images grâce à une fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images():\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(dataset[i])\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_factor = 0.5\n",
    "def add_noise(images):\n",
    "    noisy_images = images + noise_factor * tf.random.normal(shape=images.shape)\n",
    "    noisy_images = np.clip(noisy_images, 0., 1.)\n",
    "    return noisy_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_noise_dataset = add_noise(dataset)\n",
    "def display_noisy_images():\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(add_noise_dataset[i])\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "display_noisy_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE          = 128                # taille coté final d'une image en pixel (ici 28x28)\n",
    "NB_EPOCHS_DENOISE = 100               # nombre epoch alogithme debruiter\n",
    "BATCH_SIZE        = 16               # taille batch de traitement\n",
    "SAV_MODEL_DENOISE = \"denoiser_livrable2.h5\"     # sauvegarde du modele de debruitage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoded\n",
    "imput_img = Input(shape=(IMG_SIZE, IMG_SIZE, 3)) # input image dimensions\n",
    "x = layers.GaussianNoise(0.1)(imput_img)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(imput_img)\n",
    "encoded = MaxPooling2D((2, 2),padding='same')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2),padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoded\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(imput_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hystory = autoencoder.fit(add_noise_dataset, dataset,\n",
    "                          epochs=NB_EPOCHS_DENOISE,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hystory.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hystory.history['loss'], label='train_loss')\n",
    "plt.plot(hystory.history['val_loss'], label='val_loss')\n",
    "plt.title('Loss function')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the denoised images\n",
    "def display_denoised_images():\n",
    "    denoised_images = autoencoder.predict(add_noise_dataset)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(denoised_images[i])\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_denoised_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a comparison function to show original, noisy and denoised images\n",
    "def display_comparison_images():\n",
    "    add_noise_dataset = add_noise(dataset)\n",
    "    denoised_images = autoencoder.predict(add_noise_dataset)\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.suptitle(\"Comparison of Original, Noisy and Denoised Images\")\n",
    "    plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "    for i in range(4):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(dataset[i])\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.subplot(4, 4, i+5)\n",
    "        plt.imshow(add_noise_dataset[i])\n",
    "        plt.title(\"Noisy\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.subplot(4, 4, i+9)\n",
    "        plt.imshow(denoised_images[i])\n",
    "        plt.title(\"Denoised\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_comparison_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(SAV_MODEL_DENOISE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "visualkeras.layered_view(\n",
    "    autoencoder,\n",
    "    legend = True,\n",
    "    show_dimension = True,\n",
    "    spacing=50,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
