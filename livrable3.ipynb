{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> **Livrable n°3 : Captioning d'image** </center>\n",
    "\n",
    "‎ \n",
    "\n",
    "Réalisé par le **groupe n°2** :\n",
    "- BERTHO Lucien\n",
    "- BOSACKI Paul\n",
    "- GAURE Warren\n",
    "- GRENOUILLET Théo\n",
    "- VALLEMONT Hugo\n",
    "\n",
    "\n",
    "‎\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sommaire**\n",
    "\n",
    "1. [Mise en contexte](#contexte)\n",
    "2. [Objectif du livrable](#objectif)\n",
    "3. [Importation des bibliothèques](#import)\n",
    "4. [Prétraitement et exploration des données](#pretraitement)\n",
    "5. [Item #5](#item5)\n",
    "6. [Item #6](#item6)\n",
    "7. [Item #7](#item7)\n",
    "8. [Item #8](#item8)\n",
    "9. [Item #9](#item9)\n",
    "10. [Item #10](#item10)\n",
    "\n",
    "‎ \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. <a id='contexte'>Mise en contexte</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’entreprise TouNum est spécialisée dans la numérisation de documents, qu’il s’agisse de textes ou d’images. Ses services sont particulièrement sollicités par des entreprises cherchant à transformer leur base documentaire papier en fichiers numériques exploitables. Aujourd’hui, TouNum souhaite aller plus loin en enrichissant son offre avec des outils basés sur le Machine Learning.\n",
    "\n",
    "En effet, certains clients disposent d’un volume considérable de documents à numériser et expriment un besoin croissant pour des solutions de catégorisation automatique. Une telle innovation leur permettrait d’optimiser le traitement et l’exploitation de leurs données numérisées. Toutefois, TouNum ne dispose pas en interne des compétences nécessaires pour concevoir et mettre en place ces technologies.\n",
    "\n",
    "C’est dans ce cadre que notre équipe de spécialistes en Data Science du CESI est sollicitée. Notre mission consiste à développer une première solution intégrant du captioning automatique : un système capable d’analyser des photographies et de générer une légende descriptive de manière autonome.\n",
    "\n",
    "Heureusement, TouNum possède déjà plusieurs milliers d’images annotées, ce qui constituera une ressource précieuse pour entraîner les modèles de Machine Learning à partir d’un apprentissage supervisé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. <a id='objectif'>Objectif du livrable</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. <a id='import'>Importation des bibliothèques</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. <a id='pretraitement'>Prétraitement et exploration des données</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois les bibliothèques importées, nous pouvons désormais gérer les données qui nous ont été données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. <a>Vérification des images</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_directory = \"dataset_livrable_1/Photo/\"\n",
    "dataset_directory2 = \"dataset_livrable_2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_image(path):\n",
    "    try:\n",
    "        img_raw = tf.io.read_file(path)\n",
    "        _ = tf.image.decode_image(img_raw, channels=3)\n",
    "        return (path, True)\n",
    "    except Exception:\n",
    "        return (path, False)\n",
    "\n",
    "def clean_corrupted_images(directory, extensions=(\"jpg\", \"jpeg\", \"png\"), max_workers=8):\n",
    "    image_paths = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(extensions):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "\n",
    "    print(f\"Scan de {len(image_paths)} images dans {directory}\")\n",
    "\n",
    "    corrupted_count = 0\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(is_valid_image, path) for path in image_paths]\n",
    "        for future in as_completed(futures):\n",
    "            path, is_valid = future.result()\n",
    "            if not is_valid:\n",
    "                try:\n",
    "                    os.remove(path)\n",
    "                    corrupted_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur de suppression {path} : {e}\")\n",
    "\n",
    "    print(f\"Vérification terminée : {corrupted_count} image(s) corrompue(s) supprimée(s).\")\n",
    "    \n",
    "\n",
    "clean_corrupted_images(dataset_directory)\n",
    "clean_corrupted_images(dataset_directory2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. <a>Chargement des données</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_h = 128\n",
    "image_w = 128\n",
    "batch_s = 16\n",
    "\n",
    "dataset = keras.utils.image_dataset_from_directory(\n",
    "    directory = dataset_directory,\n",
    "    label_mode = None,\n",
    "    batch_size = batch_s,\n",
    "    image_size = (image_h, image_w),\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "dataset_2 = keras.utils.image_dataset_from_directory(\n",
    "    directory = dataset_directory2,\n",
    "    label_mode = None,\n",
    "    batch_size = batch_s,\n",
    "    image_size = (image_h, image_w),\n",
    "    seed = 42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. <a>Prétraitement des données</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Étant donné que nous travaillons à nouveau avec des images, c'est-à-dire des ensembles de pixels dont les valeurs sont comprises entre 0 et 255, nous devons les mettre à dans l'intervalle `[0, 1]` afin de mieux les traiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x: tf.cast(x, tf.float32) / 255.0)\n",
    "dataset_2 = dataset_2.map(lambda x: tf.cast(x, tf.float32) / 255.0)\n",
    "X = []\n",
    "\n",
    "for batch in dataset:\n",
    "    X.append(batch.numpy())\n",
    "\n",
    "for batch in dataset_2:\n",
    "    X.append(batch.numpy())\n",
    "    \n",
    "dataset = np.concatenate(X)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4. <a>Affichage des images</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que le prétraitement est fait, nous pouvons afficher des images grâce à une fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images():\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(dataset[i])\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
